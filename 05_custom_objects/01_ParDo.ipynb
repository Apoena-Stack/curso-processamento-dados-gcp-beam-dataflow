{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Funções Customizadas para Mapeamento\n",
    "\n",
    "ParDo é uma transformação Beam para processamento paralelo genérico. O paradigma de processamento ParDo é semelhante à fase “Mapa” de um algoritmo no estilo Map/Shuffle/Reduce: uma transformação ParDo considera cada elemento na PCollection de entrada, executa alguma função de processamento (seu código de usuário) naquele elemento e emite zero , um ou vários elementos em uma PCollection de saída.\n",
    "\n",
    "https://beam.apache.org/documentation/programming-guide/#pardo"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ParDo(beam.DoFn())\n",
    "\n",
    "- __init__\n",
    "- process\n",
    "- setup\n",
    "- teardown\n",
    "- start_bundle\n",
    "- finish_bundle\n",
    "\n",
    "define uma classe <-- herda de --- beam.DoFn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID\n",
      "Nome\n",
      "Nota\n",
      "Turma\n",
      "Disciplina\n",
      "1\n",
      "Iury\n",
      "10\n",
      "T1\n",
      "Mat\n",
      "2\n",
      "Davi\n",
      "8\n",
      "T1\n",
      "Mat\n",
      "3\n",
      "Vini\n",
      "6.7\n",
      "T1\n",
      "Mat\n",
      "4\n",
      "Carol\n",
      "5.4\n",
      "T1\n",
      "Mat\n",
      "5\n",
      "Helena\n",
      "7.8\n",
      "T1\n",
      "Mat\n",
      "6\n",
      "Michel\n",
      "7.7\n",
      "T2\n",
      "Mat\n",
      "7\n",
      "Fernando\n",
      "5.2\n",
      "T2\n",
      "Mat\n",
      "8\n",
      "Gabriel\n",
      "8.9\n",
      "T2\n",
      "Mat\n",
      "9\n",
      "Carla\n",
      "8.2\n",
      "T2\n",
      "Mat\n",
      "10\n",
      "Pablo\n",
      "10\n",
      "T2\n",
      "Mat\n",
      "11\n",
      "Pedro\n",
      "6.2\n",
      "T2\n",
      "Mat\n",
      "12\n",
      "Emerson\n",
      "2.1\n",
      "T2\n",
      "Mat\n",
      "13\n",
      "Iury\n",
      "9.2\n",
      "T1\n",
      "Port\n",
      "14\n",
      "Davi\n",
      "8.4\n",
      "T1\n",
      "Port\n",
      "15\n",
      "Vini\n",
      "7.8\n",
      "T1\n",
      "Port\n",
      "16\n",
      "Carol\n",
      "4.3\n",
      "T1\n",
      "Port\n",
      "17\n",
      "Helena\n",
      "6.2\n",
      "T1\n",
      "Port\n",
      "18\n",
      "Michel\n",
      "9.5\n",
      "T2\n",
      "Port\n",
      "19\n",
      "Fernando\n",
      "2.5\n",
      "T2\n",
      "Port\n",
      "20\n",
      "Gabriel\n",
      "9.0\n",
      "T2\n",
      "Port\n",
      "21\n",
      "Carla\n",
      "10\n",
      "T2\n",
      "Port\n",
      "22\n",
      "Pablo\n",
      "8.5\n",
      "T2\n",
      "Port\n",
      "23\n",
      "Pedro\n",
      "7.5\n",
      "T2\n",
      "Port\n",
      "24\n",
      "Emerson\n",
      "9.2\n",
      "T2\n",
      "Port\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<apache_beam.runners.portability.fn_api_runner.fn_runner.RunnerResult at 0x2b731d41150>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import apache_beam as beam\n",
    "\n",
    "p1 = beam.Pipeline()\n",
    "\n",
    "par_do_example = (\n",
    "    p1\n",
    "    | beam.io.ReadFromText(\"data_sample.txt\")\n",
    "    | beam.FlatMap(lambda record: record.split(\",\"))\n",
    "    | beam.FlatMap(print)\n",
    ")\n",
    "\n",
    "p1.run()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ID', 'Nome', 'Nota', 'Turma', 'Disciplina']\n",
      "['1', 'Iury', '10', 'T1', 'Mat']\n",
      "['2', 'Davi', '8', 'T1', 'Mat']\n",
      "['3', 'Vini', '6.7', 'T1', 'Mat']\n",
      "['4', 'Carol', '5.4', 'T1', 'Mat']\n",
      "['5', 'Helena', '7.8', 'T1', 'Mat']\n",
      "['6', 'Michel', '7.7', 'T2', 'Mat']\n",
      "['7', 'Fernando', '5.2', 'T2', 'Mat']\n",
      "['8', 'Gabriel', '8.9', 'T2', 'Mat']\n",
      "['9', 'Carla', '8.2', 'T2', 'Mat']\n",
      "['10', 'Pablo', '10', 'T2', 'Mat']\n",
      "['11', 'Pedro', '6.2', 'T2', 'Mat']\n",
      "['12', 'Emerson', '2.1', 'T2', 'Mat']\n",
      "['13', 'Iury', '9.2', 'T1', 'Port']\n",
      "['14', 'Davi', '8.4', 'T1', 'Port']\n",
      "['15', 'Vini', '7.8', 'T1', 'Port']\n",
      "['16', 'Carol', '4.3', 'T1', 'Port']\n",
      "['17', 'Helena', '6.2', 'T1', 'Port']\n",
      "['18', 'Michel', '9.5', 'T2', 'Port']\n",
      "['19', 'Fernando', '2.5', 'T2', 'Port']\n",
      "['20', 'Gabriel', '9.0', 'T2', 'Port']\n",
      "['21', 'Carla', '10', 'T2', 'Port']\n",
      "['22', 'Pablo', '8.5', 'T2', 'Port']\n",
      "['23', 'Pedro', '7.5', 'T2', 'Port']\n",
      "['24', 'Emerson', '9.2', 'T2', 'Port']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<apache_beam.runners.portability.fn_api_runner.fn_runner.RunnerResult at 0x2b76752ba90>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import apache_beam as beam\n",
    "\n",
    "p1 = beam.Pipeline()\n",
    "\n",
    "class SplitRow(beam.DoFn):\n",
    "    def __init__(self, split_char, *unused_args, **unused_kwargs):\n",
    "        super().__init__(*unused_args, **unused_kwargs)\n",
    "        self.split_char = split_char\n",
    "    \n",
    "    def process(self, record):\n",
    "        yield record.split(self.split_char)\n",
    "\n",
    "par_do_example = (\n",
    "    p1\n",
    "    | beam.io.ReadFromText(\"data_sample.txt\")\n",
    "    | beam.ParDo(SplitRow(split_char=\",\"))\n",
    "    # | beam.FlatMap(lambda record: record.split(\",\"))\n",
    "    | beam.FlatMap(print)\n",
    ")\n",
    "\n",
    "p1.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ID', 'Nome', 'Nota', 'Turma', 'Disciplina']\n",
      "['1', 'Iury', '10', 'T1', 'Mat']\n",
      "['2', 'Davi', '8', 'T1', 'Mat']\n",
      "['3', 'Vini', '6.7', 'T1', 'Mat']\n",
      "['4', 'Carol', '5.4', 'T1', 'Mat']\n",
      "['5', 'Helena', '7.8', 'T1', 'Mat']\n",
      "['6', 'Michel', '7.7', 'T2', 'Mat']\n",
      "['7', 'Fernando', '5.2', 'T2', 'Mat']\n",
      "['8', 'Gabriel', '8.9', 'T2', 'Mat']\n",
      "['9', 'Carla', '8.2', 'T2', 'Mat']\n",
      "['10', 'Pablo', '10', 'T2', 'Mat']\n",
      "['11', 'Pedro', '6.2', 'T2', 'Mat']\n",
      "['12', 'Emerson', '2.1', 'T2', 'Mat']\n",
      "['13', 'Iury', '9.2', 'T1', 'Port']\n",
      "['14', 'Davi', '8.4', 'T1', 'Port']\n",
      "['15', 'Vini', '7.8', 'T1', 'Port']\n",
      "['16', 'Carol', '4.3', 'T1', 'Port']\n",
      "['17', 'Helena', '6.2', 'T1', 'Port']\n",
      "['18', 'Michel', '9.5', 'T2', 'Port']\n",
      "['19', 'Fernando', '2.5', 'T2', 'Port']\n",
      "['20', 'Gabriel', '9.0', 'T2', 'Port']\n",
      "['21', 'Carla', '10', 'T2', 'Port']\n",
      "['22', 'Pablo', '8.5', 'T2', 'Port']\n",
      "['23', 'Pedro', '7.5', 'T2', 'Port']\n",
      "['24', 'Emerson', '9.2', 'T2', 'Port']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<apache_beam.runners.portability.fn_api_runner.fn_runner.RunnerResult at 0x2b7654f0c90>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import apache_beam as beam\n",
    "\n",
    "p1 = beam.Pipeline()\n",
    "\n",
    "class SplitRow(beam.DoFn):\n",
    "    def __init__(self, split_char, *unused_args, **unused_kwargs):\n",
    "        super().__init__(*unused_args, **unused_kwargs)\n",
    "        self.split_char = split_char\n",
    "    \n",
    "    def process(self, record):\n",
    "        yield record.split(self.split_char)\n",
    "    \n",
    "    def setup(self):\n",
    "        print(\"__setup__\")\n",
    "    \n",
    "    def start_bundle(self):\n",
    "        print(\"start_bundle\")\n",
    "    \n",
    "    def finish_bundle(self):\n",
    "        print(\"finish_bundle\")\n",
    "    \n",
    "    def teardown(self):\n",
    "        print(\"teardown\")\n",
    "    \n",
    "\n",
    "\n",
    "par_do_example = (\n",
    "    p1\n",
    "    | beam.io.ReadFromText(\"data_sample.txt\")\n",
    "    | beam.ParDo(SplitRow(split_char=\",\"))\n",
    "    # | beam.FlatMap(lambda record: record.split(\",\"))\n",
    "    | beam.FlatMap(print)\n",
    ")\n",
    "\n",
    "p1.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
